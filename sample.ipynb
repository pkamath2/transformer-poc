{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD - CODE - DO NOT USE #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please see sample-with-32minsTrainedData.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# or see sample-with-6hoursTrainedData.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NSynthDataSet_RawAudio import NSynthDataSet_RawAudio\n",
    "from transformers import GTransformer\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "import random, sys, math, gzip, os\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio \n",
    "import soundfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants \n",
    "\n",
    "sample_rate = 16000\n",
    "\n",
    "batch_size = 16\n",
    "lr = 0.001\n",
    "lr_warmup = 5000\n",
    "epochs = 100\n",
    "\n",
    "sample_length = 512 # For context\n",
    "embedding_size = 128 \n",
    "num_heads = 8 # Number of chunks for 'parallel/ensemble' computation\n",
    "depth = 12 # Number of transformer layers\n",
    "num_tokens = 256 #Size of the dictionary\n",
    "\n",
    "sample_index = 11\n",
    "use_temperature = True\n",
    "temperature = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GTransformer(emb=embedding_size, heads=num_heads, depth=depth, seq_length=sample_length, num_tokens=num_tokens, attention_type=None)\n",
    "model = model.cuda()\n",
    "\n",
    "opt = torch.optim.Adam(lr=lr, params=model.parameters())\n",
    "sch = torch.optim.lr_scheduler.LambdaLR(opt, lambda i: min(i / (lr_warmup / batch_size), 1.0))\n",
    "loss = torch.nn.NLLLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_dir = '/home/purnima/appdir/Github/DATA/NSynth/'\n",
    "labels_dir = '/home/purnima/appdir/Github/DATA/NSynth'\n",
    "\n",
    "validate_data_dir = os.path.join(base_data_dir,'nsynth-valid','audio')\n",
    "labels_validate_dir = os.path.join(labels_dir,'nsynth-valid', 'examples.json')\n",
    "\n",
    "validate_ds = NSynthDataSet_RawAudio(meta_data_file=labels_validate_dir, audio_dir=validate_data_dir, sr=sample_rate)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "Sampling is done as follows -  \n",
    "1. Select an input from the dataloader (update sample_index to any value from 0 to 15). Shape will be `1 X sample_length` or `1 X 512`\n",
    "2. Generate the output from the model. Shape will be `1 X 512 X 256`\n",
    "3. Retrieve the last sample from the 512 sample_length dimension `sample_data = sample_data[0, -1, :]` (argmax or temperature sampling (-- I need to understand this more--)  \n",
    "4. Append this sample to the input (from step 1). Both input and this new sample are between 0 - 255. Use this as the new input and repeat from Step 1 for as long as you want (here we are iterating through the steps 256 times to generate 256 new samples).\n",
    "5. Convert this 512 + 256 new samples to waveform using mu_expand from librosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample():\n",
    "    iterator = iter(validate_loader)\n",
    "    orig_test_data, _ = iterator.next()\n",
    "\n",
    "    test_data = orig_test_data[sample_index].view(1,-1)\n",
    "    orig_waveform = mulawDecode(test_data.view(-1).cpu())\n",
    "    test_data_ = test_data.detach().clone().cuda()\n",
    "    test_data = test_data.detach().clone().cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ind in range(int(sample_length) * 10):\n",
    "            sample_data = model(test_data) \n",
    "            if use_temperature:\n",
    "                temperature = 0.2\n",
    "                p = F.softmax(sample_data / temperature, dim=0)\n",
    "                cd = dist.Categorical(p)\n",
    "                sample_data = cd.sample()\n",
    "                sample_data = sample_data[:,-1:]\n",
    "            else:\n",
    "                sample_data = sample_data[0, -1, :].argmax() \n",
    "            \n",
    "            sample_data = sample_data.view(1,-1)\n",
    "            test_data_ = torch.cat((test_data_, sample_data), dim=1)\n",
    "            test_data = test_data_[:,test_data_.shape[1]-512:].view(1,-1)\n",
    "    \n",
    "    test_data_ = test_data_.view(-1).cpu()\n",
    "    waveform = mulawDecode(test_data_)\n",
    "    \n",
    "    return waveform, orig_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, opt, model_location):\n",
    "    checkpoint = torch.load(model_location)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    loss = checkpoint['loss']\n",
    "    epoch = checkpoint['epoch']\n",
    "    return model, opt, loss, epoch\n",
    "\n",
    "def mulawDecode(output):\n",
    "    output = output.numpy() - 127\n",
    "    waveform = librosa.mu_expand(output, quantize=True)\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt, loss, epoch = load_model(model, opt, 'checkpoint-gradclip-emblayer/attention-10.pt')\n",
    "print('Model Loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_temperature = False\n",
    "new_sample, orig_seed = sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original seed')\n",
    "plt.plot(orig_seed)\n",
    "soundfile.write('samples/orig_seed.wav', orig_seed, samplerate=sample_rate)\n",
    "Audio(orig_seed, rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('New sample appended to original seed') #First 512 samples are original seed\n",
    "plt.plot(new_sample)\n",
    "soundfile.write('samples/new_sample.wav', new_sample, samplerate=sample_rate)\n",
    "print(len(new_sample))\n",
    "Audio(new_sample, rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.5*16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data, _ = librosa.load('/home/purnima/appdir/Github/DATA/NSynth/nsynth-valid/audio/guitar_acoustic_010-084-100.wav', sr=sample_rate)\n",
    "print(_, len(audio_data))\n",
    "plt.plot(audio_data)\n",
    "audio_data = audio_data[int(3.125*16000):int(3.125*16000)+512] \n",
    "plt.figure()\n",
    "plt.plot(audio_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = librosa.mu_compress(audio_data, quantize=True) + 127\n",
    "audio_data = audio_data.astype(np.long)\n",
    "audio_data = torch.from_numpy(audio_data)\n",
    "\n",
    "test_data = audio_data.view(1,-1)\n",
    "orig_waveform = mulawDecode(test_data.view(-1).cpu())\n",
    "test_data_ = test_data.detach().clone().cuda()\n",
    "test_data = test_data.detach().clone().cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ind in range(int(sample_length) * 10):\n",
    "        sample_data = model(test_data) \n",
    "        if use_temperature:\n",
    "            temperature = 0.2\n",
    "            p = F.softmax(sample_data / temperature, dim=0)\n",
    "            cd = dist.Categorical(p)\n",
    "            sample_data = cd.sample()\n",
    "            sample_data = sample_data[:,-1:]\n",
    "        else:\n",
    "            sample_data = sample_data[0, -1, :].argmax() \n",
    "\n",
    "        sample_data = sample_data.view(1,-1)\n",
    "        test_data_ = torch.cat((test_data_, sample_data), dim=1)\n",
    "        test_data = test_data_[:,test_data_.shape[1]-512:].view(1,-1)\n",
    "\n",
    "test_data_ = test_data_.view(-1).cpu()\n",
    "waveform = mulawDecode(test_data_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original seed')\n",
    "plt.plot(orig_waveform)\n",
    "soundfile.write('samples/orig_seed.wav', orig_seed, samplerate=sample_rate)\n",
    "Audio(orig_seed, rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('New Sample')\n",
    "plt.plot(waveform)\n",
    "soundfile.write('samples/new_sample.wav', waveform, samplerate=sample_rate)\n",
    "Audio(waveform, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.display import specshow\n",
    "D = librosa.stft(orig_seed)  # STFT of y\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(S_db, x_axis='time', y_axis='linear', ax=ax)\n",
    "ax.set(title='Orig seed')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = librosa.stft(waveform)  # STFT of y\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(S_db, x_axis='time', y_axis='linear', ax=ax)\n",
    "ax.set(title='New Sample')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data, _ = librosa.load('samples/new_sample-cool.wav')\n",
    "audio_data = audio_data * 50\n",
    "plt.plot(audio_data)\n",
    "Audio(audio_data, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = librosa.stft(audio_data)  # STFT of y\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(S_db, x_axis='time', y_axis='linear', ax=ax)\n",
    "ax.set(title='New Sample')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
